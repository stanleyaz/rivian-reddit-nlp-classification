{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bde6372-d1c7-407f-8a14-8404f99a11db",
   "metadata": {},
   "source": [
    "# **Data preprocessing and modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "4e56d467-a3b4-4e4e-98cf-70f8ce2a4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, StackingClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "ee4f8732-3485-4869-a9af-58cc781f875d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cars</td>\n",
       "      <td>Need help for an article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cars</td>\n",
       "      <td>We have a 2014 Nissan Rogue. Just found out ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cars</td>\n",
       "      <td>Audi manual transmission?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cars</td>\n",
       "      <td>How much would a paint job cost to cover up tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cars</td>\n",
       "      <td>What car is Jeezy riding in this music video? ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                              title\n",
       "0      cars                           Need help for an article\n",
       "1      cars  We have a 2014 Nissan Rogue. Just found out ab...\n",
       "2      cars                          Audi manual transmission?\n",
       "3      cars  How much would a paint job cost to cover up tw...\n",
       "4      cars  What car is Jeezy riding in this music video? ..."
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev_cars = pd.read_csv('../data/ev_cars_cleaned.csv')\n",
    "\n",
    "ev_cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "207f6d94-8caf-42f0-9dc9-7a028901f49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7447, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7447 entries, 0 to 7446\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  7447 non-null   object\n",
      " 1   title      7447 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 116.5+ KB\n"
     ]
    }
   ],
   "source": [
    "print(ev_cars.shape)\n",
    "ev_cars.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29949685-69c5-4739-9d74-ce4350cb118e",
   "metadata": {},
   "source": [
    "Everything looks in order for preprocessing work to begin. Before delving into any of that, I'll split `ev_cars` into a train and test set.\n",
    "\n",
    "## Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ef04e2ec-3f9f-41d6-9347-8d1ccaa872e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5585,), (1862,), (5585,), (1862,))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ev_cars['title'], \n",
    "                                                    ev_cars['subreddit'],\n",
    "                                                    stratify= ev_cars['subreddit'],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42\n",
    "                                                   )\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305332a2-eff1-4880-af48-48ad09914535",
   "metadata": {},
   "source": [
    "There are over 5_000 samples in our train set and almost 2_000 samples in our test set. This looks like a sizeable number to train a model and test it. I feel comfortable with this, so I'll proceed.  \n",
    "\n",
    "## Baseline Accuracy - 58% as seen below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b762e1-0360-424f-a197-cd36e300c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion in the complete dataset\n",
      "cars                0.580905\n",
      "electricvehicles    0.419095\n",
      "Name: subreddit, dtype: float64\n",
      "--------------------\n",
      "Proportion in the training dataset\n",
      "cars                0.580842\n",
      "electricvehicles    0.419158\n",
      "Name: subreddit, dtype: float64\n",
      "--------------------\n",
      "Proportion in the test dataset\n",
      "cars                0.581096\n",
      "electricvehicles    0.418904\n",
      "Name: subreddit, dtype: float64\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "#The proportions of the two classes in our train and test sets approximates the proportion in our complete dataset\n",
    "print(f'Proportion in the complete dataset')\n",
    "print(ev_cars['subreddit'].value_counts(normalize=True))\n",
    "print('-'*20)\n",
    "print(f'Proportion in the training dataset')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print('-'*20)\n",
    "print(f'Proportion in the test dataset')\n",
    "print(y_test.value_counts(normalize=True))\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e09f4d-b830-45b9-9600-732ce0e8cab9",
   "metadata": {},
   "source": [
    "The baseline accuracy is 58%, this - as seen above - represents the proportion of the majority class, which in our dataset is the `cars` subreddit. If our model performs worse than this baseline accuracy, it is useless. \n",
    "\n",
    "## Preprocessing with the CountVectorizer and initializing our first model\n",
    "\n",
    "I previously used the CountVectorizer on the combined dataset for the purpose of EDA. I am going to use the CountVectorizer again now for my preprocessing and modeling. \n",
    "\n",
    "- This time I would set it up as the first stage of a pipeline. \n",
    "- The second stage of the pipeline would be an estimator. I have decided to start with a LogisticRegression model - which is a fast and versatile estimator. \n",
    "- Just like in my EDA notebook, I am going to define a custom stemmer, preprocessor, and I'll use english stopwords. \n",
    "- I'll also tune the hyperparameters in my pipeline, using a RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1182b639-84d4-4a29-a65d-279778151277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a custom stemmer function\n",
    "def my_stemmer(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    return [stemmer.stem(w) for w in text.split(\" \")]\n",
    "\n",
    "#ensuring the preprocessing is the same in my stopwords\n",
    "stemmer = SnowballStemmer('english')\n",
    "stem_stopwords = [stemmer.stem(w) for w in stopwords.words('english')]\n",
    "\n",
    "#Custom preprocessor\n",
    "def my_preprocessor(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\\\n', '', text)\n",
    "    text = re.findall(\"[\\w']+|\\$[\\d\\.]+\", text)\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d16927-9cd7-4833-9e13-656c00bb3092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.866251373424734\n",
      "The Test accuracy of this Logistic Regression model is: 0.8603651987110634\n",
      "The Misclassification rate of this Logistic Regression model is 0.13963480128893657\n",
      "The F1 score of this Logistic Regression model is 0.8839285714285714\n"
     ]
    }
   ],
   "source": [
    "pipe_1 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('logr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "#the parameters of my pipeline that would be used for tuning in the RandomizedSearchCV\n",
    "pipe_params1 = {\n",
    "    'cvec__max_features': [2800, 3000, 3500, 4000, 10000, 11000, 11500],\n",
    "    'cvec__min_df': [1, 2, 3, 4, 5],\n",
    "    'cvec__max_df': [0.9, 0.95, 0.98],\n",
    "   'cvec__ngram_range': [(1,2), (1,3), (2,2), (3,3)],\n",
    "    'logr__C': [1.4, 1.5, 2, 3, 3.5, 4]\n",
    "}\n",
    "\n",
    "#Instantiate a RandomizedSearchCV\n",
    "grid_1 = RandomizedSearchCV(pipe_1, param_distributions=pipe_params1, cv=3, n_jobs=-1, random_state=42)\n",
    "\n",
    "#fit grid_1 on the training data\n",
    "grid_1.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_1 = grid_1.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_1.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this Logistic Regression model is: {grid_1.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this Logistic Regression model is {1-grid_1.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this Logistic Regression model is {metrics.f1_score(y_test, y_pred_1, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "667d1728-0550-4d5e-8073-af698a2f251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logr__C': 3,\n",
       " 'cvec__ngram_range': (1, 3),\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__max_features': 10000,\n",
       " 'cvec__max_df': 0.98}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4a604-dd51-4661-b9d4-4f7c110648ca",
   "metadata": {},
   "source": [
    "**Some takeaways from this model**\n",
    "1. Our accuracy for this model is 86.0%. That is much better than the baseline accuracy of 58%. \n",
    "\n",
    "2. In addition, the `best_score_` of 86.6% for our training data is close to the 86.0% obtained on our test data. This indicates that our model is not overfitting and is generalizing well to unseen data. \n",
    "\n",
    "3. The model is misclassifying almost 14 out of every 100 posts. Our target is a maximum of 10 misclassifications. \n",
    "\n",
    "4. At 0.88, our `F1 score` is high and indicates a good balance between our recall and precision scores, and shows that this is a good model.\n",
    "\n",
    "## Next up, we would use a RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3476db77-f1f5-481e-8ac8-1b24163db07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8153983885407341\n",
      "The Test accuracy of this model is: 0.8018259935553169\n",
      "The Misclassification rate of this model is 0.19817400644468308\n",
      "The F1 score of this model is 0.8459290187891441\n"
     ]
    }
   ],
   "source": [
    "pipe_2 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('rf', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "#the parameters of my pipeline that would be used for tuning in the GridSearchCV\n",
    "pipe_params2 = {\n",
    "    \n",
    "    'cvec__min_df': [2, 3, 4, 5],\n",
    "    'cvec__max_features': [7500, 9000, 10000, 11000, 12000],\n",
    "    'cvec__max_df': [0.9, 0.95, 0.98, 0.99],\n",
    "    'cvec__ngram_range': [(1,2), (1,3), (2,2), (2,3)],\n",
    "    'rf__min_samples_split': [30, 40, 50, 70, 100],\n",
    "    'rf__min_samples_leaf': [30, 40, 50, 60, 70],\n",
    "    'rf__max_depth': [5,7,9,10],\n",
    "    'rf__max_features': ['auto', 0.2, 0.3, 0.4, 'log2'],\n",
    "    'rf__n_estimators': [2500, 3000, 3500, 4000]\n",
    "}\n",
    "\n",
    "grid_2 = RandomizedSearchCV(pipe_2, param_distributions=pipe_params2, cv=5, n_jobs=-1, n_iter=60, random_state=0)\n",
    "\n",
    "#fit grid_2 on the training data\n",
    "grid_2.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_2 = grid_2.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_2.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this model is: {grid_2.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-grid_2.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_2, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e580f6ab-5819-4e3b-afae-74ce8f450c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__n_estimators': 4000,\n",
       " 'rf__min_samples_split': 50,\n",
       " 'rf__min_samples_leaf': 30,\n",
       " 'rf__max_features': 0.3,\n",
       " 'rf__max_depth': 10,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__min_df': 4,\n",
       " 'cvec__max_features': 12000,\n",
       " 'cvec__max_df': 0.95}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0eb12-2ab2-440b-81ee-ea549bd09cda",
   "metadata": {},
   "source": [
    "The performance of this Random Forest model is substantially worse than that of the Logistic Regression model. We only managed an accuracy of 80.2% compared in our test data. While this is better than the baseline, it is well short of the 90% target test accuracy. Despite this model being significantly less accurate than the previous one, the F1 score of 0.85 is quite close to the 0.88 obtained in previous model. This indicates a good model.\n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "\n",
    "## Next up - Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d49d2333-0fb0-4fbc-8324-1ad068ca898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8658907788719785\n",
      "The Test accuracy of this model is: 0.8539205155746509\n",
      "The Misclassification rate of this model is 0.14607948442534913\n",
      "The F1 score of this model is 0.8710900473933649\n"
     ]
    }
   ],
   "source": [
    "pipe_3 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "#the parameters of my pipeline that would be used for tuning in the GridSearchCV\n",
    "pipe_params3 = {\n",
    "    'cvec__max_features': [9000, 10000, 11000, 12000, 13000],\n",
    "   'cvec__min_df': [1, 2, 3, 5, 6],\n",
    "   'cvec__max_df': [0.95, 0.98, 0.99],\n",
    "   'cvec__ngram_range': [(1,2), (1,3), (2,2), (1,1)],\n",
    "    'mnb__alpha': [0.1, 0.05, 0.5, 1.0]\n",
    "    } \n",
    "\n",
    "#Instantiate a RandomizedSearchCV\n",
    "grid_3 = RandomizedSearchCV(pipe_3, param_distributions=pipe_params3, cv=5, n_jobs=-1, random_state=0)\n",
    "\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_3 = grid_3.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_3.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this model is: {grid_3.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-grid_3.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_3, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "859ab5d1-2056-465f-b8c9-fcc92a4f01ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 1.0,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__max_features': 9000,\n",
       " 'cvec__max_df': 0.99}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c291ab-8d49-48aa-97ec-2150090e3e4f",
   "metadata": {},
   "source": [
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.4%|14.6%|0.87|\n",
    "\n",
    "At this point, since my three models so far have failed to achieve my target accuracy, I would like to tackle this classification problem via other ensemble methods, with the expectation that combining multiple models together would produce a more powerful model. Next would be a Bagging Classifier, using LogisticRegression as the base estimator (even though LR model do not overfit easily, I have decided to use this in my Bagging Classifier just because the LR model has performed the best of all my models so far). \n",
    "\n",
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6ac1cd3-9555-43a1-9591-6f4b145fe41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleyaz/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8689346463742167\n",
      "The Test accuracy of this model is: 0.8678839957035446\n",
      "The Misclassification rate of this model is 0.13211600429645542\n",
      "The F1 score of this model is 0.8906666666666667\n"
     ]
    }
   ],
   "source": [
    "pipe_4 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('bag', BaggingClassifier(base_estimator=LogisticRegression(), random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipe_params4 = {\n",
    "    'cvec__max_features': [10000, 11000, 12000, 13000],\n",
    "    'cvec__min_df': [2, 3, 5],\n",
    "    'cvec__max_df': [0.95, 0.98, 0.99],\n",
    "   'cvec__ngram_range': [(1,2), (1,3), (2,2), (1,1)],\n",
    "    'bag__n_estimators': [10, 50, 100, 150],\n",
    "    'bag__base_estimator__C': [0.001, 2.5, 3, 3.5]\n",
    "}\n",
    "\n",
    "\n",
    "grid_4 = RandomizedSearchCV(pipe_4, param_distributions=pipe_params4, cv=5, n_jobs=-1, random_state=0)\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_4 = grid_4.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_4.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this model is: {grid_4.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-grid_4.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_4, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329b5363-2fde-4172-8adb-a7ba9a057744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__ngram_range': (1, 3),\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__max_features': 12000,\n",
       " 'cvec__max_df': 0.95,\n",
       " 'bag__n_estimators': 150,\n",
       " 'bag__base_estimator__C': 2.5}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_4.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11b243-efa5-443c-b2c0-8b9705d442c8",
   "metadata": {},
   "source": [
    "The above bagged classifier using Logistic Regression as the base estimator is now slightly our best model so far with a test accuracy of 86.8%, and an F1 score of almost 0.9.  \n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "\n",
    "Can we try this bagging method again, using a Random Forest classifier instead? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bae0805-1c9f-4003-854b-dd4001dd649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stanleyaz/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8726947179946285\n",
      "The Test accuracy of this model is: 0.8651987110633728\n",
      "The Misclassification rate of this model is 0.13480128893662724\n",
      "The F1 score of this model is 0.8872923215087561\n"
     ]
    }
   ],
   "source": [
    "pipe_5 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('bag', BaggingClassifier(base_estimator=RandomForestClassifier()))\n",
    "])\n",
    "\n",
    "pipe_params5 = {\n",
    "    'cvec__max_features': [10000, 11000],\n",
    "    'cvec__min_df': [2, 3, 5],\n",
    "    'cvec__max_df': [0.95, 0.98],\n",
    "   'cvec__ngram_range': [(1,2), (1,3)],\n",
    "    #'bag__n_estimators': [100, 150, 200],\n",
    "    'bag__base_estimator__max_depth': [200, 250, 300],\n",
    "    'bag__base_estimator__n_estimators': [150, 400]\n",
    "}\n",
    "\n",
    "\n",
    "grid_5 = RandomizedSearchCV(pipe_5, param_distributions=pipe_params5, cv=5, n_jobs=-1, random_state=0)\n",
    "\n",
    "grid_5.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_5 = grid_5.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_5.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this model is: {grid_5.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-grid_5.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_5, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "802f40b1-5d73-4be1-b6b6-807826c02517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__ngram_range': (1, 2),\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__max_features': 10000,\n",
       " 'cvec__max_df': 0.95,\n",
       " 'bag__base_estimator__n_estimators': 400,\n",
       " 'bag__base_estimator__max_depth': 200}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693e6c42-3a12-4862-a507-1b2d731be627",
   "metadata": {},
   "source": [
    "The two bagging models I have built have similar performances. Approximately equal R1 scores of 0.89, and an accuracy of over 86%. The LR base estimator bagging model only slightly outperforms the RF base estimator, but as noted earlier, it still falls a amall percentage short of our target.\n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "|5|Bagged Classifier with RF base estimator|86.5%|13.5%|0.89|\n",
    "\n",
    "Next, I am going to attempt a boosting technique. Boosting is generally thought to reduce bias which is what I am hoping to achieve in this problem. My preferred boosting technique for this problem would be the GradientBoosting classifier.\n",
    "\n",
    "## GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c373962-b334-44c2-a36f-7f231bacd7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8725156669650851\n",
      "The Test accuracy of this model is: 0.864124597207304\n",
      "The Misclassification rate of this model is 0.13587540279269605\n",
      "The F1 score of this model is 0.887305122494432\n"
     ]
    }
   ],
   "source": [
    "pipe_6 = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=0, max_features='sqrt'))\n",
    "])\n",
    "\n",
    "pipe_params6 = {\n",
    "    'cvec__max_features': [10000, 11000, 12000],\n",
    "    'cvec__min_df': [2, 3, 5],\n",
    "    'cvec__max_df': [0.95, 0.98, 0.99],\n",
    "   'cvec__ngram_range': [(1,2), (1,3), (2,2)],\n",
    "    'gb__learning_rate': [0.8, 0.1, 1.0],\n",
    "    'gb__max_depth': [10, 5, 7, 2],\n",
    "    'gb__n_estimators': [100, 125, 300],\n",
    "}\n",
    "\n",
    "\n",
    "grid_6 = RandomizedSearchCV(pipe_6, param_distributions=pipe_params6, cv=5, n_jobs=-1, random_state=0)\n",
    "\n",
    "grid_6.fit(X_train, y_train)\n",
    "\n",
    "#make predictions\n",
    "y_pred_6 = grid_6.predict(X_test)\n",
    "\n",
    "print(f'Train score: {grid_6.best_score_}')\n",
    "\n",
    "print(f'The Test accuracy of this model is: {grid_6.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-grid_6.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_6, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29e26d72-f81c-4bfe-a788-cbf974257eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gb__n_estimators': 300,\n",
       " 'gb__max_depth': 10,\n",
       " 'gb__learning_rate': 0.1,\n",
       " 'cvec__ngram_range': (1, 3),\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__max_features': 12000,\n",
       " 'cvec__max_df': 0.98}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_6.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26be997-84c5-47ad-81a5-4938068c9fe4",
   "metadata": {},
   "source": [
    "It appears most of our ensemble models are performing similarly. THis boosting model has same F1 score as the last two and similar accuracy as well.\n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "|5|Bagged Classifier with RF base estimator|86.5%|13.5%|0.89|\n",
    "|6|Gradient Boosting|86.4%|13.6%|0.89|\n",
    "\n",
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eeafa1e9-7149-4619-850e-6f3e2b5a7f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8825425246195167\n",
      "The Test accuracy of this model is: 0.8711063372717508\n",
      "The Misclassification rate of this model is 0.1288936627282492\n",
      "The F1 score of this model is 0.8924731182795699\n"
     ]
    }
   ],
   "source": [
    "#Going to use logistic regression, MNB, adaboost and gradient boost in pipelines that would be fed into my voting classifier\n",
    "\n",
    "logr_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('logr', LogisticRegression())])\n",
    "    \n",
    "mnb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('mnb', MultinomialNB())])\n",
    "\n",
    "ada_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('ada', AdaBoostClassifier(base_estimator=LogisticRegression()))])\n",
    "\n",
    "gb_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('gb', GradientBoostingClassifier())])\n",
    "\n",
    "vote = VotingClassifier([\n",
    "    ('logr_pipe', logr_pipe),\n",
    "    ('mnb_pipe', mnb_pipe),\n",
    "    ('ada_pipe', ada_pipe),\n",
    "    ('gb_pipe', gb_pipe)\n",
    "], voting='soft', n_jobs=-1)\n",
    "\n",
    "#Fit\n",
    "vote.fit(X_train, y_train)\n",
    "\n",
    "#predict\n",
    "y_pred_8 = vote.predict(X_test)\n",
    "\n",
    "print(f'Train accuracy: {cross_val_score(vote, X_train, y_train).mean()}')\n",
    "\n",
    "# Test score\n",
    "print(f'The Test accuracy of this model is: {vote.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-vote.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_8, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd40d29-e3c5-4e17-a081-b7ee114ecde2",
   "metadata": {},
   "source": [
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "|5|Bagged Classifier with RF base estimator|86.5%|13.5%|0.89|\n",
    "|6|Gradient Boosting|86.4%|13.6%|0.89|\n",
    "|7|Voting Classifier|87.1%|12.9%|0.89|\n",
    "\n",
    "## Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b475831-09d7-4d37-8c80-1321dc6834dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using four level one estimators - logr, mnb, rf and bagging. The final estimator would be a logistic reg\n",
    "l1_estimator = [\n",
    "    ('logr_pipe', Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('logr', LogisticRegression())])),\n",
    "    ('mnb_pipe', Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('mnb', MultinomialNB())])),\n",
    "    ('rf_pipe', Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('rf', RandomForestClassifier())])),\n",
    "    ('bag_pipe', Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))),\n",
    "    ('bag', BaggingClassifier(base_estimator=LogisticRegression(C=3)))]))]\n",
    "\n",
    "stacked_model_3 = StackingClassifier(estimators=l1_estimator,\n",
    "                                 final_estimator=LogisticRegression(C=3, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e206cbf-ee68-421e-9aa3-1b9c09c1b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8859444941808416\n",
      "The Test accuracy of this model is: 0.8737916219119226\n",
      "The Misclassification rate of this model is 0.1262083780880774\n",
      "The F1 score of this model is 0.8934240362811792\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "stacked_model_3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_7 = stacked_model_3.predict(X_test)\n",
    "\n",
    "# Cross-val score\n",
    "print(f'Train accuracy: {cross_val_score(stacked_model_3, X_train, y_train).mean()}')\n",
    "\n",
    "# Test score\n",
    "print(f'The Test accuracy of this model is: {stacked_model_3.score(X_test, y_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-stacked_model_3.score(X_test, y_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(y_test, y_pred_7, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa804e-9de7-4b2e-a1b8-33b5745e8e59",
   "metadata": {},
   "source": [
    "At 87.4% test accuracy, this stacked model is now our best performing model. It performs well and does not overfit (88.6% vs 87.4% for train and test scores respectively). As with our last three models, the F1 score of this model also comes in at a high 0.89. \n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "|5|Bagged Classifier with RF base estimator|86.5%|13.5%|0.89|\n",
    "|6|Gradient Boosting|86.4%|13.6%|0.89|\n",
    "|7|Voting Classifier|87.1%|12.9%|0.89|\n",
    "|8|Stacked Classifier|87.4%|12.6%|0.89|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212aefd4-3bdb-4fac-8fdf-64331ef7a861",
   "metadata": {},
   "source": [
    "## Some more feature engineering\n",
    "\n",
    "## Adding the character length feature\n",
    "\n",
    "Recall during the EDA that there was a small difference in the length of the characters between the titles in the `r/electricvehicles` subreddit compared to the `r/cars` subreddit. It was not a huge difference - an average of 59 characters for the `r/electricvehicles` subreddit compared to 52 for the `r/cars` subreddit. However, I wonder if including that character lengths column could help my models in making better predictions. I'll try that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "67dd4b74-a1b9-45fb-8772-c4782016e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ev_cars['title']\n",
    "y = ev_cars['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "cbd8788a-d7ac-4222-9052-0600d00db6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7447, 72350)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now I will initiate a countvectorizer, then fit_transform the title columns, then convert to df\n",
    "\n",
    "cvt_1 = CountVectorizer(stop_words= stem_stopwords, tokenizer=my_stemmer, preprocessor=my_preprocessor, ngram_range=(1,3))\n",
    "\n",
    "X_vect = cvt_1.fit_transform(X)\n",
    "\n",
    "X_vect_df = pd.DataFrame(X_vect.todense(), columns=cvt_1.get_feature_names_out())\n",
    "X_vect_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "8baec53f-68da-4a7a-816f-17c5c591be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that would help me in adding the new feature. Adapted from this Kaggle piece - https://www.kaggle.com/code/pceccon/countvectorizer-and-tfidf-strategies/notebook\n",
    "\n",
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features\n",
    "    \"\"\"\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "32a793db-be61-4a4d-aacd-16c4e0723fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7447x72351 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136468 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding the character length feature using the defined function above\n",
    "\n",
    "X_vect_df = add_feature(X_vect_df, X.str.len())\n",
    "X_vect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "b2165768-ac81-479d-8631-b2912b528b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5585, 72351), (1862, 72351), (5585,), (1862,))"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train-test split\n",
    "Xl_train, Xl_test, yl_train, yl_test = train_test_split(X_vect_df, y,stratify=y, random_state=42)\n",
    "Xl_train.shape, Xl_test.shape, yl_train.shape, yl_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "6be3e2a7-69b6-4dd6-a88b-44c6db4365a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My best model was the stacked classifier. I am going to use that model on this df that has my aditional length column\n",
    "\n",
    "l2_estimator = [\n",
    "    ('logr', LogisticRegression(C=3, max_iter=30000)),\n",
    "    ('mnb', MultinomialNB()),\n",
    "    ('rf', RandomForestClassifier()),\n",
    "    ('bag', BaggingClassifier(base_estimator=LogisticRegression(C=3, max_iter=30000)))]\n",
    "\n",
    "stacked_model_4 = StackingClassifier(estimators=l2_estimator,\n",
    "                                 final_estimator=LogisticRegression(C=3, random_state = 1, max_iter=30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "b9fd8b5a-ba1a-498c-8687-dc25ed826f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8837958818263205\n",
      "The Test accuracy of this model is: 0.8780880773361976\n",
      "The Misclassification rate of this model is 0.12191192266380235\n",
      "The F1 score of this model is 0.8966772872098315\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "stacked_model_4.fit(Xl_train, yl_train)\n",
    "\n",
    "y_pred_9 = stacked_model_4.predict(Xl_test)\n",
    "\n",
    "# Cross-val score\n",
    "print(f'Train accuracy: {cross_val_score(stacked_model_4, Xl_train, yl_train).mean()}')\n",
    "\n",
    "# Test score\n",
    "print(f'The Test accuracy of this model is: {stacked_model_4.score(Xl_test, yl_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-stacked_model_4.score(Xl_test, yl_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(yl_test, y_pred_9, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f8dedf0b-6e68-4d6b-8a75-5495e2e6aa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l3_estimator = [\n",
    "    ('logr', LogisticRegression(C=3, max_iter=20000)),\n",
    "    ('mnb', MultinomialNB()),\n",
    "    ('ada', RandomForestClassifier()),\n",
    "    ('bag', BaggingClassifier(base_estimator=LogisticRegression(C=3, max_iter = 20000)))]\n",
    "\n",
    "stacked_model_5 = StackingClassifier(estimators=l3_estimator,\n",
    "                                 final_estimator=LogisticRegression(C=3, random_state=1, max_iter=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "feac8360-f98c-421d-ac25-509b08aa3b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8871978513876455\n",
      "The Test accuracy of this model is: 0.8791621911922664\n",
      "The Misclassification rate of this model is 0.12083780880773365\n",
      "The F1 score of this model is 0.8969258589511755\n"
     ]
    }
   ],
   "source": [
    "# Fit\n",
    "stacked_model_5.fit(Xl_train, yl_train)\n",
    "\n",
    "y_pred_10 = stacked_model_5.predict(Xl_test)\n",
    "\n",
    "# Cross-val score\n",
    "print(f'Train accuracy: {cross_val_score(stacked_model_5, Xl_train, yl_train).mean()}')\n",
    "\n",
    "# Test score\n",
    "print(f'The Test accuracy of this model is: {stacked_model_5.score(Xl_test, yl_test)}')\n",
    "print(f'The Misclassification rate of this model is {1-stacked_model_5.score(Xl_test, yl_test)}')\n",
    "print(f'The F1 score of this model is {metrics.f1_score(yl_test, y_pred_9, pos_label = \"cars\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa88a74-f8c8-48e2-a900-16f15556e43d",
   "metadata": {},
   "source": [
    "**Running scores:**\n",
    "\n",
    "|Model Number|Model Type|Test Accuracy Achieved|Misclassification Rate|F1 Score|\n",
    "|---|---|---|---|---|\n",
    "|1|Logistic Regression|86.0%|14.0%|0.88|\n",
    "|2|Random Forest|80.2%|19.8%|0.85|\n",
    "|3|Multinomial Naive Bayes|85.3%|14.7%|0.87|\n",
    "|4|Bagged Classifier with LR base estimator|86.8%|13.2%|0.89|\n",
    "|5|Bagged Classifier with RF base estimator|86.5%|13.5%|0.89|\n",
    "|6|Gradient Boosting|86.4%|13.6%|0.89|\n",
    "|7|Voting Classifier|87.1%|12.9%|0.89|\n",
    "|8|Stacked Classifier|87.4%|12.6%|0.89|\n",
    "|9|Stacked Classifier with character length feature|87.9%|12.1%|0.90|\n",
    "\n",
    "**Important Takeaway:**\n",
    "\n",
    "Adding the character lengths as a feature has slightly improved the model. Our accuracy is now at 87.9%, and the model is only misclassifying about 12 of 100 posts. Most importantly, our F1 score is now at 0.90, meaning that this model has achieved one of the prerequisites given by my boss at the beginning of the project to achieve an F1 Score of 0.90. Even though the accuracy did not hit the 0.90 mark, hitting 0.90 for the F1 score means our model meets one of two criteria given. Hence, this is the model I will recommend for production.\n",
    "\n",
    "## Visualizing our top 5 models\n",
    "All our top models performed much better than the baseline accuracy of 58%. They all had high accuracy and F1 scores with minimal misclassifications. I expect the bar chart below to have bars close to each other indicating the similarity of performances of our models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "fc22bd59-ea66-441f-a038-0cc558b8059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacked Classifier with length</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacked Classifier</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagged Classifier</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Accuracy  F1 Score\n",
       "0  Stacked Classifier with length     0.879     0.897\n",
       "1              Stacked Classifier     0.874     0.893\n",
       "2               Voting Classifier     0.871     0.892\n",
       "3               Bagged Classifier     0.868     0.891\n",
       "4               Gradient Boosting     0.864     0.887"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dataframe of our top 5 models and the scores for each\n",
    "\n",
    "d = {'Model': ['Stacked Classifier with length', 'Stacked Classifier', 'Voting Classifier', 'Bagged Classifier', 'Gradient Boosting'],\n",
    "'Accuracy': [0.879, 0.874, 0.871, 0.868, 0.864],\n",
    "'F1 Score': [0.897, 0.893, 0.892, 0.891, 0.887]}\n",
    "\n",
    "models = pd.DataFrame(data=d)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "f3949a87-fe7e-4b0a-b7a6-6c599ecf811a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "p = models.plot(x = 'Model',\n",
    "                   kind='barh', \n",
    "                   stacked=False, \n",
    "                   figsize=(14,8), \n",
    "                   fontsize=15, width = 0.7)\n",
    "\n",
    "p.axvline(linewidth=4, color='r', x=0.58)\n",
    "\n",
    "p.invert_yaxis()\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('All 5 top models perform much better than the baseline accuracy (in red)', size=17, fontweight='bold')\n",
    "plt.ylabel('Model', size=20, fontweight='bold'),\n",
    "plt.yticks(fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/top_models.png', dpi=300);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c3c8e5-81fc-4cf1-bcf1-f946581aee64",
   "metadata": {},
   "source": [
    "## Are there posts that our two top models are both misclassifying? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "e4612fca-a48e-4d72-ac48-e22c8dbe9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss(preds):\n",
    "    \"\"\"\n",
    "    Function returns a dataframe of misclassified posts when predicted values\n",
    "    are provided as arguments. \n",
    "    `preds` can be any model's model.predict(X_test) result\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df['predictions'] = preds \n",
    "    df['true_values'] = list(y_test)\n",
    "    df['title'] = list(X_test)\n",
    "    return df[df['predictions'] != df['true_values']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "6f512554-3c7b-4b45-bcfe-1848e92af02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_values</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cars</td>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>Flat Out in My Rimac Nevera in Monaco! 0-100 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>U.S. auto sales to fall in 2022, GM set to rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>A Farewell to the Internal Combustion Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>For U.S. Companies, the Race for the New EV Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>Hello! I am a research student researching the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         predictions       true_values  \\\n",
       "7               cars  electricvehicles   \n",
       "12  electricvehicles              cars   \n",
       "23  electricvehicles              cars   \n",
       "24  electricvehicles              cars   \n",
       "26  electricvehicles              cars   \n",
       "\n",
       "                                                title  \n",
       "7   Flat Out in My Rimac Nevera in Monaco! 0-100 i...  \n",
       "12  U.S. auto sales to fall in 2022, GM set to rec...  \n",
       "23       A Farewell to the Internal Combustion Engine  \n",
       "24  For U.S. Companies, the Race for the New EV Ba...  \n",
       "26  Hello! I am a research student researching the...  "
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing function on one of our predictions\n",
    "\n",
    "miss(y_pred_9).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "46d1e9ad-f263-4b89-b08b-7b5639e94d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our top model is misclassifying 225 posts\n",
      "Our next best model is misclassifying 235 posts\n",
      "There are 210 posts that are being misclassified both by our top model and the next best model\n"
     ]
    }
   ],
   "source": [
    "#How many posts are being misclassified by both our top performing model and the next best performing model?\n",
    "\n",
    "a = miss(y_pred_10)  #our top model\n",
    "b = miss(y_pred_7)   #our second top model\n",
    "\n",
    "print(f'Our top model is misclassifying {a.shape[0]} posts')\n",
    "print(f'Our next best model is misclassifying {b.shape[0]} posts')\n",
    "\n",
    "total = 0\n",
    "for r in a.index:\n",
    "    if r in b.index:\n",
    "        total+=1\n",
    "print(f'There are {total} posts that are being misclassified both by our top model and the next best model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "c218eab4-0439-4f6f-912c-49b1d04c93e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_values</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cars</td>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>Flat Out in My Rimac Nevera in Monaco! 0-100 i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>U.S. auto sales to fall in 2022, GM set to rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>A Farewell to the Internal Combustion Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>For U.S. Companies, the Race for the New EV Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>electricvehicles</td>\n",
       "      <td>cars</td>\n",
       "      <td>Hello! I am a research student researching the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         predictions       true_values  \\\n",
       "7               cars  electricvehicles   \n",
       "12  electricvehicles              cars   \n",
       "23  electricvehicles              cars   \n",
       "24  electricvehicles              cars   \n",
       "26  electricvehicles              cars   \n",
       "\n",
       "                                                title  \n",
       "7   Flat Out in My Rimac Nevera in Monaco! 0-100 i...  \n",
       "12  U.S. auto sales to fall in 2022, GM set to rec...  \n",
       "23       A Farewell to the Internal Combustion Engine  \n",
       "24  For U.S. Companies, the Race for the New EV Ba...  \n",
       "26  Hello! I am a research student researching the...  "
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at some of the posts being misclassified\n",
    "explore = a.head()\n",
    "explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "3b8eb5bc-72ec-45e7-95b1-7743f281681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['For U.S. Companies, the Race for the New EV Battery Is On',\n",
       " 'Hello! I am a research student researching the opinions on electric cars. Please help me by completing my 1-minute survey for this project. Thank you.']"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consider the last two posts\n",
    "[a['title'][i] for i in explore.index[-2:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf275d-408c-4127-bd1c-0658245b6f5d",
   "metadata": {},
   "source": [
    "**The last post from above reads thus**: \n",
    "\n",
    ">Hello! I am a research student researching the opinions on electric cars. Please help me by completing my 1-minute survey for this project. Thank you. \n",
    "\n",
    "If anyone had shown this to me and asked me to guess which subreddit it would belong to, I'll most likely go for `r/electricvehicles`. That's sensible. And that's what our models went for. The problem is it was actually posted in the `r/cars` subreddit. \n",
    "\n",
    "**Next to it**\n",
    "\n",
    ">For U.S. Companies, the Race for the New EV Battery Is On\n",
    "\n",
    "Another one for which I would have chosen the `r/electricvehicles` subreddit - just like our models did - but was actually posted in the `r/cars` subreddit.\n",
    "\n",
    "There were several others like these from either class, wrongly predicted by the model, but which truly could have gone either way. This is not surprising. The two subreddits are very similar, and arguably a majority of posts shared on one could legitimately be shared on the other. Considering all that, I believe that an accuracy of 88% is solid. \n",
    "\n",
    "## Conclusions & Recommendations\n",
    "\n",
    "Recall that my assignment was to:\n",
    "1. Collect more data from the two subreddits, using [Pushshift's](https://github.com/pushshift/api) API.\n",
    "**Outcome: I collected enough data from the two subreddits. The number was high enough to give me confidence about my models' abilities to solve the task.** \n",
    "\n",
    "2. Use Natural Language Processing to train a classifier on which subreddit a given post came from. \n",
    "**Outcome: I trained several high performing predictive models with accuracies far above the baseline. I was informed that before the model can be put into production, it had to either achieve 90% accuracy or an F1 score of 90%. While none of my models managed to reach 90% accuracy, one of my models achieved an F1 score of 90%. That model was a stacked classifier comprising of LogisticRegression, Multinomial Naive Bayes, RandomForestClassifier, and Bagging Classifier as the first level estimators; and a Logisticregression model as the final estimator.** \n",
    "\n",
    "3. Make a presentation outlining my process and findings.\n",
    "**A powerpoint presentation is included in this project and would be delivered as requested.** \n",
    "\n",
    "**My recommendations are as follows:**\n",
    "- I have submitted my findings as requested, but if there is more time I would love to incorporate the texts of the posts as well. I only used the titles in this instance, but I believed that adding the texts could further help my models in differentiating between the classes. \n",
    "- I recommend that my Stacked Classifier which got the highest F1 score be put into production as it meets the 0.90 F1 score criteria. Further its other metrics, including an accuracy of 88% and a misclassification rate of 12 out of 100 is solid enough to proceed with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c34a910-45d4-41b0-ace7-d645c44cff9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
